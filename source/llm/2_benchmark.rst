Benchmark for evaluating the performance of the LLM model
=========================================================


Open Source Benchmark
---------------------

#. taide-bench-eval

   - https://github.com/taide-taiwan/taide-bench-eval


Paper 
-----

#. :cite:year:`zheng2023judging` :title-ref:`zheng2023judging`

